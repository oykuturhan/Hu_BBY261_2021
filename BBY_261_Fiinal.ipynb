{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oykuturhan/Hu_BBY261_2021/blob/projeler/BBY_261_Fiinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "vYWEIVPtz9-6",
        "outputId": "9e3f7ff2-7903-4e3c-ec19-983536a7e5ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "Number of images in x_train 60000\n",
            "Number of images in x_test 10000\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 35s 18ms/step - loss: 0.2057 - accuracy: 0.9370\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0828 - accuracy: 0.9745\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0576 - accuracy: 0.9815\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0445 - accuracy: 0.9854\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0352 - accuracy: 0.9883\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0539 - accuracy: 0.9837\n",
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01cb6cf560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "7\n",
            "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f01cb6cf560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "[3]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "image_index = 7777 # You may select anything up to 60,000\n",
        "print(y_train[image_index]) # The label is 8\n",
        "plt.imshow(x_train[image_index], cmap='Greys')\n",
        "\n",
        "x_train.shape\n",
        "\n",
        "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('Number of images in x_train', x_train.shape[0])\n",
        "print('Number of images in x_test', x_test.shape[0])\n",
        "\n",
        "# Importing the required Keras modules containing model and layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "# Creating a Sequential Model and adding the layers\n",
        "model = Sequential()\n",
        "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model.add(Dense(128, activation=tf.nn.relu))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=x_train,y=y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "image_index = 0\n",
        "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
        "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
        "print(pred.argmax())\n",
        "\n",
        "#PNG = \"/content/drive/MyDrive\"\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "png = Image.open(\"/content/drive/MyDrive/üç.png\").convert (\"L\")\n",
        "png = np.resize(png, (28, 28, 1))\n",
        "pngBinary = np.array(png)\n",
        "plt.imshow(pngBinary.reshape(28, 28))\n",
        "\n",
        "tahminEt = model.predict(pngBinary.reshape(1, 28, 28, 1))\n",
        "tahminSayı = np.argmax(model.predict(pngBinary.reshape(1, 28, 28, 1)), axis=-1)\n",
        "\n",
        "print(tahminEt)\n",
        "print(tahminSayı)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n526rL_vbqTz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "BBY_261_Fiinal.ipynb",
      "provenance": [],
      "mount_file_id": "16DOXAQ1pAuul8tiFTXVf-AXZMU_9H_AZ",
      "authorship_tag": "ABX9TyNjZtReIWjy9KWeRwKc9rvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}